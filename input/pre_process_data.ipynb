{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This program reads data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from os import listdir\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import random \n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize words\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# list of stops words to be removed\n",
    "stop_words = stopwords.words('english')\n",
    "# max number of email for each class\n",
    "# spam does has les than 2000 \n",
    "max_email = 1500\n",
    "max_spam = 1700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gets the path of the spam email that is in the junk_email files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function gets the emails from the junk email folder\n",
    "def get_spam_email(): \n",
    "    spam_path=[]\n",
    "    path_mail = 'maildir'\n",
    "\n",
    "    for maildir in listdir(path_mail):\n",
    "        maildir_path = path.join(path_mail, maildir)\n",
    "\n",
    "        for mails in listdir(maildir_path):\n",
    "            emails_spam = path.join(maildir_path, mails)\n",
    "\n",
    "            if 'junk_email' == mails:   \n",
    "                #print(emails_spam)\n",
    "                for e in listdir(emails_spam):\n",
    "                    #print(e)\n",
    "                    if '.ipynb_checkpoints' == e:\n",
    "                        continue               \n",
    "                    spam_path.append(path.join(emails_spam, e))\n",
    "                    '''store the first 2000 spam emails'''\n",
    "                    if len(spam_path) > max_spam:\n",
    "                        break\n",
    "            \n",
    "    return spam_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gets the path of the email that is in the sent files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emails():\n",
    "    email_path=[]\n",
    "    path_mail = 'maildir'\n",
    "    \n",
    "    for maildir in listdir(path_mail):\n",
    "        maildir_path = path.join(path_mail, maildir)\n",
    "\n",
    "        for mails in listdir(maildir_path):\n",
    "            emails_spam = path.join(maildir_path, mails)\n",
    "\n",
    "            # checking if there is a file that does not belong to the folders\n",
    "            if path.isfile(emails_spam):\n",
    "                continue\n",
    "            \n",
    "            for e in listdir(emails_spam):\n",
    "              \n",
    "                if path.isfile(e): \n",
    "                    print(e)\n",
    "                    continue\n",
    "                    \n",
    "                if path.isdir(e):\n",
    "                    print(e)\n",
    "                    continue\n",
    "                if e in ['clickathome', 'gas', 'loaddata','enron_accelerator']:\n",
    "                    print(\"never see this\")\n",
    "                    continue               \n",
    "                email_path.append(path.join(emails_spam, e))\n",
    "          \n",
    "    return email_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ramdomize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      ".ipynb_checkpoints\n",
      ".ipynb_checkpoints\n",
      "never see this\n",
      "never see this\n",
      ".ipynb_checkpoints\n",
      ".ipynb_checkpoints\n",
      ".ipynb_checkpoints\n",
      "never see this\n",
      "never see this\n",
      ".ipynb_checkpoints\n",
      ".ipynb_checkpoints\n",
      ".ipynb_checkpoints\n",
      ".ipynb_checkpoints\n",
      ".ipynb_checkpoints\n",
      ".ipynb_checkpoints\n",
      ".ipynb_checkpoints\n",
      ".ipynb_checkpoints\n",
      ".ipynb_checkpoints\n",
      "never see this\n",
      "never see this\n",
      ".ipynb_checkpoints\n",
      ".ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "# gets the paths files\n",
    "spam_email_path = get_spam_email()\n",
    "email_path      = get_emails()\n",
    "random.seed(89)\n",
    "random.shuffle(spam_email_path)\n",
    "random.shuffle(email_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It tokenize the sentences and remove the stop words \n",
    "def tokenize_rm_stop_word(line):\n",
    "    line = tokenizer.tokenize(line)\n",
    "    line = [w for w in line if not w in stop_words]       \n",
    "    return line "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gets the non-spam from the folders and store it into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_text=[]\n",
    "for em_sp_path in spam_email_path:\n",
    "    with open (em_sp_path) as read:\n",
    "        line = read.readlines()[15:]\n",
    "        temp=[]\n",
    "        for ln in line:\n",
    "            ln = ln.lower().strip()\n",
    "            if len(ln) == 0:\n",
    "                continue\n",
    "            # removing all character that is not a letter or number\n",
    "            #ln2 = re.sub(r'[^a-zA-Z0-9\\s]', ' ', ln)\n",
    "            #ln2 = re.sub(r'[^a-zA-Z\\s]', ' ', ln)\n",
    "            ln2 = re.sub(r'[^a-zA-Z]', ' ', ln)\n",
    "            \n",
    "            ln2 = ln2.split()\n",
    "            ln2 = ' '.join(ln2)\n",
    "            # remove stop workds\n",
    "            #ln3 = tokenize_rm_stop_word(ln2)\n",
    "            # make it string again \n",
    "            #ln3 = ' '.join(ln3)\n",
    "            temp.append(ln2)\n",
    "\n",
    "        spam_text.append(' '.join(temp))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http www jumpsociety com hello i have visited www jumpsociety com and noticed that your website is not listed on some search engines i am sure that through our service the number of people who visit your website will definitely increase seekercenter is a unique technology that instantly submits your website to over search engines and directories a really low cost and effective way to advertise your site for more details please go to seekercenter net give your website maximum exposure today looking forward to hearing from you best regards vanessa lintner sales marketing www seekercenter net you are receiving this email because you opted in to receive special offers through a partner website if you feel that you received this email in error or do not wish to receive additional special offers please enter your email address here and click the button of remove me'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gets the emails from the folders and store it into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_of_emails(email_path):\n",
    "    \n",
    "    email_text=[]\n",
    "    \n",
    "    for em_path in email_path:\n",
    "        try:\n",
    "            with open (em_path) as read:\n",
    "                temp=[]\n",
    "                start_reading=False\n",
    "                \n",
    "\n",
    "                for line in read.readlines():\n",
    "                    if 'X-FileName:' in line:\n",
    "                        start_reading = True\n",
    "                        continue\n",
    "                    if start_reading:\n",
    "\n",
    "                        line = line.lower().strip()\n",
    "                        if len(line) == 0:\n",
    "                            continue\n",
    "                        # removing all character that is not a letter or number\n",
    "                        #line = re.sub(r'[^a-zA-Z0-9\\s]', ' ', line)\n",
    "                        #line = re.sub(r'[^a-zA-Z\\s]', ' ', line)\n",
    "                        line = re.sub(r'[^a-zA-Z]', ' ', line)\n",
    "\n",
    "                        line = line.split()\n",
    "                        line = ' '.join(line)\n",
    "\n",
    "                        # remove stop workds\n",
    "                        #ln3 = tokenize_rm_stop_word(ln2)\n",
    "                        # make it string again \n",
    "                        #ln3 = ' '.join(ln3)\n",
    "                        temp.append(line)\n",
    "        except:\n",
    "            print(\"Could not open \",em_path)\n",
    "            continue\n",
    "        email_text.append(' '.join(temp))\n",
    "    return email_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492685"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(email_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open  maildir/gay-r/sent/59.\n",
      "1499\n",
      "Could not open  maildir/taylor-m/inbox/enron_south\n",
      "1499\n",
      "Could not open  maildir/hyvl-d/miscellaneous/parking\n",
      "1499\n",
      "Could not open  maildir/mcconnell-m/tw_accounts/pepl\n",
      "Could not open  maildir/taylor-m/online_trading/product_descriptions\n",
      "1498\n",
      "Could not open  maildir/griffith-j/vpp/brazos_lp\n",
      "Could not open  maildir/shapiro-r/2002_budget/2001_budget\n",
      "Could not open  maildir/germany-c/bankrupt/tdc_energy\n",
      "1497\n",
      "Could not open  maildir/mcconnell-m/tw_accounts/astra\n",
      "Could not open  maildir/shackleton-s/all_documents/2856.\n",
      "Could not open  maildir/baughman-d/ubsw_energy/transmission\n",
      "1497\n",
      "Could not open  maildir/symes-k/deal_communication/cal_px\n",
      "Could not open  maildir/beck-s/inbox/100.\n",
      "Could not open  maildir/sanders-r/deleted_items/duke\n",
      "1497\n",
      "Could not open  maildir/baughman-d/enron_power/24_hour\n",
      "Could not open  maildir/mclaughlin-e/private_folders/corp_info_announcements\n",
      "Could not open  maildir/taylor-m/inbox/emissions_e_mail\n",
      "Could not open  maildir/presto-k/presto_working_files/resumes\n",
      "Could not open  maildir/presto-k/presto_working_files/ees_2_ways\n",
      "Could not open  maildir/hayslett-r/projects/lng__global_\n",
      "1494\n",
      "Could not open  maildir/taylor-m/inbox/training\n",
      "Could not open  maildir/germany-c/bankrupt/sempra\n",
      "Could not open  maildir/beck-s/egm/price__brent\n",
      "1497\n",
      "Could not open  maildir/gilbertsmith-d/ercot/pricing\n",
      "1499\n",
      "Could not open  maildir/mcconnell-m/tw_projects/agave_tie_in\n",
      "1499\n",
      "1500\n",
      "Could not open  maildir/ybarbo-p/deleted_items/83.\n",
      "1499\n",
      "Could not open  maildir/bass-e/inbox/paintball\n",
      "Could not open  maildir/stokley-c/chris_stokley/mid_markt\n",
      "Could not open  maildir/taylor-m/online_trading/credit_derivatives\n",
      "Could not open  maildir/taylor-m/all_documents/3474.\n",
      "1496\n",
      "Could not open  maildir/germany-c/notes/bankruptcy\n",
      "1499\n",
      "Could not open  maildir/mcconnell-m/tw_accounts/aquila\n",
      "1499\n",
      "Could not open  maildir/kitchen-l/_americas/finance\n",
      "1499\n",
      "Could not open  maildir/taylor-m/inbox/passwords\n",
      "Could not open  maildir/hayslett-r/projects/eott\n",
      "1498\n",
      "1500\n",
      "Could not open  maildir/kitchen-l/_americas/south_america\n",
      "Could not open  maildir/kitchen-l/_americas/netco_canada\n",
      "Could not open  maildir/baughman-d/power/customer_trip2001\n",
      "Could not open  maildir/davis-d/inbox/wells\n",
      "1496\n",
      "Could not open  maildir/baughman-d/personal/travel\n",
      "1499\n",
      "1500\n",
      "1500\n",
      "Could not open  maildir/baughman-d/enron_power/fundamentals\n",
      "1499\n",
      "Could not open  maildir/shackleton-s/all_documents/2374.\n",
      "Could not open  maildir/benson-r/inbox/large_messages\n",
      "1498\n",
      "Could not open  maildir/taylor-m/inbox/options\n",
      "Could not open  maildir/campbell-l/all_documents/1014.\n",
      "Could not open  maildir/hyatt-k/inbox/enron_news\n",
      "1497\n",
      "Could not open  maildir/kaminski-v/c/technote\n",
      "1499\n",
      "Could not open  maildir/shankman-j/deleted_items/510.\n",
      "1499\n",
      "Could not open  maildir/kitchen-l/_americas/asset_marketing\n",
      "Could not open  maildir/baughman-d/enron_power/personel_vac\n",
      "Could not open  maildir/taylor-m/inbox/archieves_coal_news\n",
      "Could not open  maildir/davis-d/2_trash/candis\n",
      "Could not open  maildir/hyvl-d/miscellaneous/asset_group\n",
      "1495\n",
      "Could not open  maildir/corman-s/inbox/tw_neg_rates\n",
      "Could not open  maildir/hayslett-r/projects/egas\n",
      "Could not open  maildir/griffith-j/deleted_items/1175.\n",
      "1497\n",
      "Could not open  maildir/mccarty-d/inbox/alaska_gas\n",
      "Could not open  maildir/shankman-j/personal/12.\n",
      "Could not open  maildir/kitchen-l/_americas/europe\n",
      "Could not open  maildir/blair-l/deleted_items/_sent_mail\n",
      "1496\n",
      "Could not open  maildir/mcconnell-m/tw_projects/misc_tie_ins\n",
      "Could not open  maildir/stokley-c/chris_stokley/iso\n",
      "Could not open  maildir/beck-s/egm/lng\n",
      "1497\n",
      "Could not open  maildir/horton-s/all_documents/64.\n",
      "1499\n",
      "Could not open  maildir/white-s/personnel/training\n",
      "Could not open  maildir/beck-s/prc/assoc_2000_ye\n",
      "Could not open  maildir/kean-s/california/ballot_initiative\n",
      "1497\n",
      "1500\n",
      "Could not open  maildir/germany-c/bankrupt/bridgeline\n",
      "1499\n",
      "1500\n",
      "Could not open  maildir/williams-j/private_folders/passwords\n",
      "1499\n",
      "Could not open  maildir/mccarty-d/inbox/m_a\n",
      "Could not open  maildir/shapiro-r/deleted_items/patriotism\n",
      "1498\n",
      "Could not open  maildir/hayslett-r/projects/acquisitions\n",
      "Could not open  maildir/shackleton-s/notes_inbox/1491.\n",
      "1498\n",
      "Could not open  maildir/taylor-m/inbox/analyst_prog\n",
      "Could not open  maildir/presto-k/presto_working_files/personnel_issues\n",
      "Could not open  maildir/gilbertsmith-d/ercot/recs\n",
      "Could not open  maildir/scholtes-d/credit/risk\n",
      "Could not open  maildir/hyatt-k/tw/el_paso\n",
      "1495\n",
      "Could not open  maildir/mccarty-d/inbox/weekly_bullets\n",
      "Could not open  maildir/steffes-j/california_issues/western_gas\n",
      "Could not open  maildir/kitchen-l/_americas/tax\n",
      "1497\n",
      "1500\n",
      "Could not open  maildir/mccarty-d/inbox/tw\n",
      "Could not open  maildir/kitchen-l/_americas/sec\n",
      "1498\n",
      "1500\n",
      "Could not open  maildir/taylor-m/inbox/so2\n",
      "Could not open  maildir/hyvl-d/miscellaneous/cle\n",
      "1498\n",
      "Could not open  maildir/schoolcraft-d/tw/tw_map\n",
      "Could not open  maildir/heard-m/inbox/master_netting\n",
      "Could not open  maildir/baughman-d/ubsw_energy/ubsw_online\n",
      "Could not open  maildir/stokley-c/chris_stokley/enron_corp\n",
      "1496\n",
      "Could not open  maildir/baughman-d/power/legal_agreements\n",
      "1499\n",
      "Could not open  maildir/horton-s/discussion_threads/60.\n",
      "1499\n",
      "Could not open  maildir/shapiro-r/deleted_items/221.\n",
      "Could not open  maildir/baughman-d/enron_power/mdea\n",
      "Could not open  maildir/germany-c/bankrupt/enron_compressor_services\n",
      "1497\n"
     ]
    }
   ],
   "source": [
    "number_of_batches = 50\n",
    "max_email=1500\n",
    "emails_text = []\n",
    "start=0\n",
    "stop=max_email\n",
    "\n",
    "for i in range(number_of_batches):\n",
    "    batch = email_path[start:stop]\n",
    "    \n",
    "    txt = get_batch_of_emails(batch)\n",
    "    print(len(txt))\n",
    "    emails_text.append(txt)\n",
    "    start = stop\n",
    "    stop = stop + max_email\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Email:  1499\n",
      "Total Spams:  1360\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Email: \", len(emails_text[1]))\n",
    "print(\"Total Spams: \", len(spam_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save list into a CSV file for better display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(emails_text)):\n",
    "    path = 'batches/email_batch_'+ str(i+1) +'.csv'\n",
    "    with open(path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([ \"email\", \"category\"])\n",
    "\n",
    "        for j in range(len(emails_text[i])):\n",
    "            writer.writerow([emails_text[i][j], 0])\n",
    "            \n",
    "        for k in range(len(spam_text)):\n",
    "            writer.writerow([spam_text[k], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "tokenized_word=[]\n",
    "fdist = FreqDist()\n",
    "for i in emails_text[4]:\n",
    "  \n",
    "    for word in word_tokenize(i):\n",
    "        fdist[word] += 1\n",
    "        \n",
    "fdist.plot(30,cumulative=False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_word=[]\n",
    "fdist = FreqDist()\n",
    "for i in spam_text:\n",
    "  \n",
    "    for word in word_tokenize(i):\n",
    "        fdist[word] += 1\n",
    "        \n",
    "fdist.plot(30,cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
